{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "asteroid-prediction.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b11e5b7"
      },
      "source": [
        "# Predicting Diameter and Potential Harm of Asteroids using Machine Learning\n",
        "\n",
        "**Authors** :\n",
        "Colin Campbell (c_c953), Jake Worden (jrw294), Leah Lewis (lrl68) and Ryan Wakabayashi (rjw102)\n",
        "\n",
        "This uses the Asteroid dataset:  https://www.kaggle.com/basu369victor/prediction-of-asteroid-diameter"
      ],
      "id": "5b11e5b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43599ad2"
      },
      "source": [
        "# Part 1 : Predicting Diameter"
      ],
      "id": "43599ad2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4956d26a"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Load python packages for data prepartion and analysis."
      ],
      "id": "4956d26a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PzBhcp5PPsl"
      },
      "source": [
        "# Predicting Diameter and Physical Harm of Asteroids using Machine Learning\n",
        "**Authors** :\n",
        "Colin Campbell (c_c953), Jake Worden (jrw294), Leah Lewis (lrl68) and Ryan Wakabayashi (rjw102)\n",
        "\n",
        "**Abstract** :  [  ]"
      ],
      "id": "3PzBhcp5PPsl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt_QrpfTPWH_"
      },
      "source": [
        "## Introduction\n",
        "\n",
        " \n",
        "\n",
        " "
      ],
      "id": "zt_QrpfTPWH_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68c58i10PdC_"
      },
      "source": [
        "## Problem Statement \n",
        "Question: How to use machine learning to predict the diameter of asteroids and classify them as physically hazardous.\n",
        "* Asteroid diameter prediction based upon Asteroid_Updated.csv from Kaggle.\n",
        "* Predict whether an asteroid is physically hazardous to Earth. \n",
        "\n",
        "* Success measures:\n",
        "\t* 5 - 10 fold CV accuracy for all models\n",
        "\t* Regression models: R^2 score\n",
        "\t* Classification models: Precision, Recall, ROC/AUC\n",
        "\t\n",
        "* Hope to achieve >85% R^2 for regression models (based upon kaggle responses) and then >=80% precision and recall for the classification models (low goal based on amount of data for imbalanced classes)."
      ],
      "id": "68c58i10PdC_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXUWhVcvPst7"
      },
      "source": [
        "### Related Work\n",
        "\n",
        "**Link to other work:** [Asteroid Diameter Estimators with added difficulty](https://www.kaggle.com/liamkesatoran/asteroid-diameter-estimators-with-added-difficulty)"
      ],
      "id": "HXUWhVcvPst7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1bMdj7LP18_"
      },
      "source": [
        "## Data Management \n",
        "- Describe how did you evaluate your solution\n",
        "- What evaluation metrics did you use?\n",
        "- Describe a baseline system\n",
        "- How much did your system outperform the baseline?\n",
        "- Were there other systems evaluated on the same dataset? How did your system do in comparison to theirs?\n",
        "- Show graphs/tables with results\n",
        "- Error analysis\n",
        "- Suggestions for future improvements\n",
        "\n",
        "Description of the dataset (dimensions, names of variables with their description)"
      ],
      "id": "-1bMdj7LP18_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx3izY9jQFjT"
      },
      "source": [
        "### Data Gathering\n"
      ],
      "id": "Gx3izY9jQFjT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTrxHhyaQL9I"
      },
      "source": [
        "#### *Motivation*\n",
        "This database was acquired from the Jet Propulsion Laboratory at California Institute of Technology's \"Solar System Dynamics\" on behalf of NASA. This information is related to the orbits, physical and characteristics, and discovery cirumstances for most known natural bodies in our solar system\n"
      ],
      "id": "tTrxHhyaQL9I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p_HO92KQR5R"
      },
      "source": [
        "#### *Composition*\n",
        "\t\n",
        "| Feature | Description | Dtype | Null |\n",
        "| ------- | ----------------- | ------ | :------: |\n",
        "| a | Semi-major axis(au) | float64 | 2 |\n",
        "| e | Eccentricity | float64 | 0 |\n",
        "| i | Inclination with respect to x-y ecliptic plain(deg) | float64 | 0 |\n",
        "| om | Longitude of the ascending node | float64 | 0 |\n",
        "| w | Argument of perihelion | float64 | 0 |\n",
        "| q | Perihelion distance(au) | float64 | 0 |\n",
        "| ad | Aphelion distance(au) | float64 | 6 |\n",
        "| per_y | Oribital period(YEARS) | float64 | 1 |\n",
        "| data_arc | Data arc-span(d) | float64 | 15474 |\n",
        "| condition_code | Orbit condition code | object | 867 |\n",
        "| n_obs_used | Number of Observation used | int64 | 0 |\n",
        "| H | Absolute magnitude parameter | float64 | 2689 |\n",
        "| neo | Near Earth Object | object | 6 |\n",
        "| pha | Physically Hazardous Asteroid | object | 16442 |\n",
        "| diameter | Diameter of asteroid(Km) | object | 702078 |\n",
        "| extent | Object bi/tri axial ellipsoid dimensions(Km) | object | 839696 |\n",
        "| albedo | Geometric albedo | float64 | 703305 |\n",
        "| rot_per | Rotation Period(h) | float64 | 820918 |\n",
        "| GM | Standard gravitational parameter, Product of mass and gravitational constant | float64 | 839700 |\n",
        "| BV | Color index B-V magnitude difference | float64 | 838693 |\n",
        "| UB | Color index U-B magnitude difference | float64 | 838735 |\n",
        "| IR | Color index I-R magnitude difference | float64 | 839713 |\n",
        "| spec_B | Spectral taxonomic type(SMASSII) | object | 838048 |\n",
        "| spec_T | Spectral taxonomic type(Tholen) | object | 838734 |\n",
        "| G | Magnitude slope parameter | float64 | 839595 |\n",
        "| moid | Earth minimum orbit intersection distance(au) | float64 | 16442 |\n",
        "| class | Asteroid orbit class | object | 0 |\n",
        "| n | Mean motion(deg/d) | float64 | 2 |\n",
        "| per | Orbital period(d) | float64 | 6 |\n",
        "| ma | Mean anomaly(deg) | float64 | 8 |\n",
        "\n",
        "* Shape: (839714 , 31)\n",
        "* Memory usage: 198.6+ MB\n",
        "\n",
        "**Dataset found here:** [Asteroid_Updated.csv](https://www.kaggle.com/basu369victor/prediction-of-asteroid-diameter?select=Asteroid_Updated.csv)"
      ],
      "id": "3p_HO92KQR5R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUAle7zJQY7_"
      },
      "source": [
        "### Data Pre-processing, Cleaning, Labeling, and Maintenance \n",
        "\n",
        "- Read in the .csv and visualized .head() and .info()\n",
        "- Checked the number of Null values. If the sum of null values are > 700,000, we dropped the column\n",
        "- If the remaining column has only Nulls, it is dropped\n",
        "- If the remaining rows contain any Nulls, it is dropped"
      ],
      "id": "SUAle7zJQY7_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "684738b6",
        "outputId": "c871fefe-689d-4a05-a951-af85268b5f74"
      },
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv(\"Asteroid_Updated.csv\")\n",
        "df.info()"
      ],
      "id": "684738b6",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 839714 entries, 0 to 839713\n",
            "Data columns (total 31 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   name            21967 non-null   object \n",
            " 1   a               839712 non-null  float64\n",
            " 2   e               839714 non-null  float64\n",
            " 3   i               839714 non-null  float64\n",
            " 4   om              839714 non-null  float64\n",
            " 5   w               839714 non-null  float64\n",
            " 6   q               839714 non-null  float64\n",
            " 7   ad              839708 non-null  float64\n",
            " 8   per_y           839713 non-null  float64\n",
            " 9   data_arc        824240 non-null  float64\n",
            " 10  condition_code  838847 non-null  object \n",
            " 11  n_obs_used      839714 non-null  int64  \n",
            " 12  H               837025 non-null  float64\n",
            " 13  neo             839708 non-null  object \n",
            " 14  pha             823272 non-null  object \n",
            " 15  diameter        137636 non-null  object \n",
            " 16  extent          18 non-null      object \n",
            " 17  albedo          136409 non-null  float64\n",
            " 18  rot_per         18796 non-null   float64\n",
            " 19  GM              14 non-null      float64\n",
            " 20  BV              1021 non-null    float64\n",
            " 21  UB              979 non-null     float64\n",
            " 22  IR              1 non-null       float64\n",
            " 23  spec_B          1666 non-null    object \n",
            " 24  spec_T          980 non-null     object \n",
            " 25  G               119 non-null     float64\n",
            " 26  moid            823272 non-null  float64\n",
            " 27  class           839714 non-null  object \n",
            " 28  n               839712 non-null  float64\n",
            " 29  per             839708 non-null  float64\n",
            " 30  ma              839706 non-null  float64\n",
            "dtypes: float64(21), int64(1), object(9)\n",
            "memory usage: 198.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b303df2"
      },
      "source": [
        "Print the sum of null values to determine which columns had a high percentage of null values."
      ],
      "id": "2b303df2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adbc5771",
        "outputId": "016106fa-fa6e-4abc-a6a8-e1808686c468"
      },
      "source": [
        "print(df.shape)\n",
        "print(df.isnull().sum())"
      ],
      "id": "adbc5771",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(839714, 31)\n",
            "name              817747\n",
            "a                      2\n",
            "e                      0\n",
            "i                      0\n",
            "om                     0\n",
            "w                      0\n",
            "q                      0\n",
            "ad                     6\n",
            "per_y                  1\n",
            "data_arc           15474\n",
            "condition_code       867\n",
            "n_obs_used             0\n",
            "H                   2689\n",
            "neo                    6\n",
            "pha                16442\n",
            "diameter          702078\n",
            "extent            839696\n",
            "albedo            703305\n",
            "rot_per           820918\n",
            "GM                839700\n",
            "BV                838693\n",
            "UB                838735\n",
            "IR                839713\n",
            "spec_B            838048\n",
            "spec_T            838734\n",
            "G                 839595\n",
            "moid               16442\n",
            "class                  0\n",
            "n                      2\n",
            "per                    6\n",
            "ma                     8\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2c9d9d6"
      },
      "source": [
        "Drop the columns with high amount of null values. Keeping diameter since it is the target."
      ],
      "id": "e2c9d9d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98115f66",
        "outputId": "53bf086e-247a-4e47-d1f7-473128d0ed5a"
      },
      "source": [
        "columns = ['name', 'extent', 'albedo', 'rot_per', 'GM', 'BV', 'G', 'UB', 'IR', 'spec_B', 'spec_T']\n",
        "df = df.drop(columns=columns)\n",
        "print(df.shape)\n",
        "print(df.isnull().sum())"
      ],
      "id": "98115f66",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(839714, 20)\n",
            "a                      2\n",
            "e                      0\n",
            "i                      0\n",
            "om                     0\n",
            "w                      0\n",
            "q                      0\n",
            "ad                     6\n",
            "per_y                  1\n",
            "data_arc           15474\n",
            "condition_code       867\n",
            "n_obs_used             0\n",
            "H                   2689\n",
            "neo                    6\n",
            "pha                16442\n",
            "diameter          702078\n",
            "moid               16442\n",
            "class                  0\n",
            "n                      2\n",
            "per                    6\n",
            "ma                     8\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b29bedee"
      },
      "source": [
        "After running into issues with incorrect datatypes, we found we needed to go through the data and turn the values into numerical values and those that did not become numeric, were dropped.\n",
        "\n",
        "We then printed the sum of nulls to check that the dataframe had no null values."
      ],
      "id": "b29bedee"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ec9d609",
        "outputId": "1fa58d7f-4eef-4710-ef89-af42ca7981e3"
      },
      "source": [
        "df = df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
        "df['diameter'].astype(float)\n",
        "df.dropna(how='all', axis=1, inplace=True)\n",
        "df.dropna(how='any', axis=0, inplace=True)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.isnull().sum())\n",
        "print(df.dtypes)"
      ],
      "id": "8ec9d609",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(136759, 17)\n",
            "a                 0\n",
            "e                 0\n",
            "i                 0\n",
            "om                0\n",
            "w                 0\n",
            "q                 0\n",
            "ad                0\n",
            "per_y             0\n",
            "data_arc          0\n",
            "condition_code    0\n",
            "n_obs_used        0\n",
            "H                 0\n",
            "diameter          0\n",
            "moid              0\n",
            "n                 0\n",
            "per               0\n",
            "ma                0\n",
            "dtype: int64\n",
            "a                 float64\n",
            "e                 float64\n",
            "i                 float64\n",
            "om                float64\n",
            "w                 float64\n",
            "q                 float64\n",
            "ad                float64\n",
            "per_y             float64\n",
            "data_arc          float64\n",
            "condition_code    float64\n",
            "n_obs_used          int64\n",
            "H                 float64\n",
            "diameter          float64\n",
            "moid              float64\n",
            "n                 float64\n",
            "per               float64\n",
            "ma                float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6crj_N_RgyL"
      },
      "source": [
        "### Exploratory Data Analysis \n",
        "\n",
        "What Data Acquisition, Cleaning, and Processing Tools have you used.  Why? \n",
        "\n",
        "* Describe the methods you explored (usually algorithms, or data cleaning or wrangling approaches). \n",
        "* Justify your methods in terms of the problem statement. \n",
        "* What did you consider but *not* use? In particular, be sure to include every method you tried, even if it didn't \"work\". "
      ],
      "id": "D6crj_N_RgyL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIGpx4HPRnRc"
      },
      "source": [
        "## Machine Learning Approaches\n",
        "\n",
        "In this section, you could describe the methods you used in your analysis. For example, if you are doing classifications, you could introduce the methods like logistic regression, discriminant analysis, support vector machines. You don't have to write formulas if you don't want to do so. It is fine to describe the methods in words. This section basically is a description of the methodologies that you have used for analyzing your data. (up to 2pages)\n",
        "Describe the choice of Machine Learning Tool.  Refer ro related work, if applicable.  \n",
        "\n",
        "* Evaluate a primary model and in addition a \"baseline\" model. \n",
        "  * The baseline is typically the simplest model that's applicable to that data problem\n",
        "    * Naive Bayes for classification\n",
        "\t* K-means on raw feature data for clustering.\n",
        "* Evaluate state-of-art model \n",
        "  * Research gitHuib, paperswithcode, Kaggle and similar. \n",
        "  * If not applicable, talk to the instructor.  \n",
        "  \n",
        "**Hint** Goal is to have some sort of baseline evaluation by Nov 11th checkpoint to establish a scale by which to measure your project's performance. Compare the performance of your baseline model and primary model and explain the differences.\n",
        "\n",
        "** This is where all the methods you have tried go, including state-of-art if any **"
      ],
      "id": "UIGpx4HPRnRc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qghs-LGORqlX"
      },
      "source": [
        "### Describe the ML methods that you used and the reasons for their choice. \n",
        "What is the family of machine learnign algorithms you are using and why? \n",
        "* Supervised or Unsupervised?\n",
        "* Regression or classification?"
      ],
      "id": "Qghs-LGORqlX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDrmstW-Rtcz"
      },
      "source": [
        "### Justify ML algorithms in terms of the problem itself and the methods you want to use. \n",
        "* How did you employ them? \n",
        "* What features worked well and what didn't?\n",
        "* Provide documentation for integration  "
      ],
      "id": "dDrmstW-Rtcz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRkCPS8YRvg4"
      },
      "source": [
        "### Tools and Infrastructure Tried and Not Used\n",
        "\n",
        "Describe any tools and infrastruicture that you tried and ended up not using.\n",
        "What was the problem? \n",
        "Describe infrastructure used. "
      ],
      "id": "wRkCPS8YRvg4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoXpypmARyRH"
      },
      "source": [
        "## Experiments\n",
        "\n",
        "Give a detailed summary of the results of your work.\n",
        "\n",
        " * Setup - Here is where you specify the exact performance measures you used.  \n",
        "   * Describe the data used in experiment for presenting dataset: Datasheets for Dataset template \n",
        "   * Describe your accuracy or quality measure, and your performance (runtime or throughput) measure. \n",
        "   \n",
        " * Please use visualizations whenever possible. Include links to interactive visualizations if you built them. \n",
        " \n",
        " * You can also submit a separated notebook as an appendix to your report if that makes the visualization/interaction task easier. \n",
        "   * It would be reasonable to submit your report as a notebook, but please make sure it runs on one of the two standard environments, and that you include any required files. "
      ],
      "id": "xoXpypmARyRH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwCLvvZQR1o9"
      },
      "source": [
        "## Conclusion\n",
        "In this section give a high-level summary of your results. If the reader only reads one section of the report, this one should be it, and it should be self-contained.  You can refer back to the Experiments Section for elaborations. This section should be less than a page. In particular emphasize any results that were surprising."
      ],
      "id": "EwCLvvZQR1o9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj7T851TR3I_"
      },
      "source": [
        "## References\n",
        "List the references that cited in your project."
      ],
      "id": "Dj7T851TR3I_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGKLyQzqR5ar"
      },
      "source": [
        "## Appendix## \n",
        "\n",
        "Explain the contributions of each member to the project. Include all supporting materials, e.g., additional figures/tables, Python code technical derivations."
      ],
      "id": "HGKLyQzqR5ar"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ac67b02"
      },
      "source": [
        "## Determine Feature Selection"
      ],
      "id": "5ac67b02"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db9a996c"
      },
      "source": [
        "# ANOVA on features on target to determine which features are significant\n",
        "#anova = SelectKBest(k=10)\n",
        "# fitting ANOVA model with features and target\n",
        "#anova.fit(x, y)\n",
        "\n",
        "# origin airport causes most effect in model\n",
        "#for i in range(len(x.columns)):\n",
        "   # print(f'{x.columns[i]}: {anova.scores_[i]}')"
      ],
      "id": "db9a996c",
      "execution_count": null,
      "outputs": []
    }
  ]
}